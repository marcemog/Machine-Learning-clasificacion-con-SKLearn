# -*- coding: utf-8 -*-
"""Machine Learning: Clasificación con SKLearn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16zHGABYc956Ud8sYZM8fMvuAUS9PFb7U

#Machine Learning: Clasificación con SKLearn

En este notebook estaremos desarrollando varios ejercicios para entender como funcionan algunos algoritmos de clasificacion

##Aula 1: Introducción a la clasificación
"""

#features   1=si   0=no
#tiene el pelo largo?
#tiene las uñas afiladas?
#hace miau?


perro1 = [0,1,1]
perro2 = [1,0,1]
perro3 = [1,1,1]

gato1 = [0,1,0]
gato2 = [0,1,1]
gato3 = [1,1,0]

x_train = [perro1, perro2, perro3, gato1, gato2, gato3]  #datos
y_train = [1,1,1,0,0,0]                #1 es perro y 0 es gato   #serian las clases a la que pertenece cada animal

from sklearn.svm import LinearSVC

model = LinearSVC()
model.fit(x_train,y_train)

animal_misterioso = [1,1,1]
model.predict([animal_misterioso])

misterio1 = [1,1,1]
misterio2 = [1,1,0]
misterio3 = [0,1,1]

x_test = [misterio1, misterio2, misterio3]   #pruebas
y_test = [0,1,1]    #clase_pruebas

previsiones = model.predict(x_test)

correctos = (previsiones == y_test).sum()
total = len(x_test)
tasa_de_acierto = correctos/total

print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

from sklearn.metrics import accuracy_score

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

#las x se refieren a los atributos y las y se refieren a la clasificacion o target

"""##Aula2: Pruebas replicables, estratificación, lectura de datos por internet"""

import pandas as pd
uri = 'https://gist.githubusercontent.com/ahcamachod/38673f75b54ec62ffc290eff8e7c716e/raw/6eaa07e199d9f668bf94a034cb84dac58c82fa4f/tracking.csv'  #son datos de un ecommerce para analizar el comportamiento de los clientes
datos = pd.read_csv(uri)
datos.sample(5)

mapa = {
        'home' : 'principal',
        'how_it_works' : 'como_funciona',
        'contact' : 'contacto',
        'bought' : 'compró'
      }

datos = datos.rename(columns = mapa)
datos.sample(3)

x = datos[['principal','como_funciona','contacto']]
x.head()

y = datos.compró
y.head()

datos.shape

x_train = x[:75]  #toma los primeros 75 registros para entrenar el modelo
y_train = y[:75]  #toma los primeros 75 registros para entrenar el modelo
x_test = x[75:]   #toma los ultimos 24 registros para realizar pruebas
y_test = y[75:]   #toma los ultimos 24 registros para realizar pruebas

y_train.value_counts()

24/74

y_test.value_counts()

9/25

print(f'Entrenaremos con {len(x_train)} elementos y probaremos con {len(x_test)} elementos')

from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

model = LinearSVC()
model.fit(x_train,y_train)
previsiones = model.predict(x_test)

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

#otra forma de hacerlo si tenemos un DataFrame muy grande o desconocemos el tamaño
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25)   #estamos asignando un 25% del DataFrame para pruebas

model = LinearSVC()
model.fit(x_train,y_train)
previsiones = model.predict(x_test)

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

#otra forma de hacerlo si tenemos un DataFrame muy grande o desconocemos el tamaño
from sklearn.model_selection import train_test_split

seed = 42 #debemos asignar un seed para garantizar la aletoreidad y lograr que el resultado sea replicable, de lo contrario al ejecutar como la celda de arriba sin el seed el resultado cambia cada vez que se ejecuta

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state = seed)   #estamos asignando un 25% del DataFrame para pruebas

model = LinearSVC()
model.fit(x_train,y_train)
previsiones = model.predict(x_test)

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

# es importante establecer un estado de aleatoreidad siempre que realizamos machine learning porque de esta manera garantizaremos que el resultado se pueda reproducir

#otra forma de hacerlo si tenemos un DataFrame muy grande o desconocemos el tamaño
from sklearn.model_selection import train_test_split

seed = 42 #debemos asignar un seed para garantizar la aletoreidad y lograr que el resultado sea replicable, de lo contrario al ejecutar como la celda de arriba sin el seed el resultado cambia cada vez que se ejecuta

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state = seed, stratify=y)   #estamos asignando un 25% del DataFrame para pruebas

model = LinearSVC()
model.fit(x_train,y_train)
previsiones = model.predict(x_test)

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

#es muy importante usar el parametro stratify para asegurar que las proporciones en este caso de y se mantengan semenjantes al realizar el entrenamiento y en las pruebas
#para que no haya ningun problema de clasificacion para el algoritmo
# vamos a hacer una estratificación para realizar nuestra separación de las bases de entrenamiento y de prueba, de modo que quede la misma proporción de las clases en ambos casos.
#Por ejemplo, si en mi dataset de entrenamiento el 30% de las clasificaciones pertenecen a la clase = 1, entonces lo ideal es que mi dataset de pruebas tenga también el 30% de sus 
#clasificaciones como clase = 1. Para ello, configuraremos el parámetro stratify=y para que haga la estratificación con base en la clasificación.

y_train.value_counts()

25/74

y_test.value_counts()

8/25

"""##Aula3: Proyecto de baja dimensionalidad y Baseline"""

uri = 'https://gist.githubusercontent.com/ahcamachod/7c55640f0d65bcbd31bb986bb599180c/raw/1b616e97a8719b3ff245fcdd68eaebdb8da38082/projects.csv'
datos = pd.read_csv(uri)
datos.head()

mapa = {
        'unfinished':'no_finalizado',
        'expected_hours':'horas_esperadas',
        'price':'precio'
        }

datos = datos.rename(columns = mapa)
datos.sample(3)

cambio = {1:0 , 0:1}
datos['finalizado'] = datos.no_finalizado.map(cambio)
datos.sample(5)

import seaborn as sns

sns.scatterplot(data=datos, x= 'horas_esperadas',y='precio' );

sns.scatterplot(data=datos, x= 'horas_esperadas',y='precio', hue='finalizado' );

#se observa que a medida que las horas y el precio aumentan el trabajo suele finalizarse, mientras que si el trabajo tiene muchas horas y el precio se mantiene bajo no se finaliza

sns.relplot(data=datos, x= 'horas_esperadas',y='precio', hue='finalizado', col = 'finalizado');

#vamos a entrenar un modelo de machine learning que va a determinar si el proyecto sera finalizado o no

import numpy as np

x = datos[['horas_esperadas', 'precio']]
y = datos.finalizado

seed = 42 #debemos asignar un seed para garantizar la aletoreidad y lograr que el resultado sea replicable, de lo contrario al ejecutar como la celda de arriba sin el seed el resultado cambia cada vez que se ejecuta
np.random.seed(seed) #evitamos tener que especificar el random_state en la linea de abajo

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, stratify=y)   #estamos asignando un 25% del DataFrame para pruebas
print(f'Entrenaremos con {len(x_train)} elementos y probaremos con {len(x_test)} elementos')

model = LinearSVC()
model.fit(x_train,y_train)
previsiones = model.predict(x_test)

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

base_previsiones = np.ones(540)
tasa_de_acierto = accuracy_score(y_test, base_previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

sns.scatterplot(data= x_test, x= 'horas_esperadas',y='precio', hue=y_test );

x_min = x_test.horas_esperadas.min()
x_max = x_test.horas_esperadas.max()
y_min = x_test.precio.min()
y_max = x_test.precio.max()

pixels = 100
eje_x = np.arange(x_min, x_max, (x_max - x_min)/pixels)
eje_y = np.arange(y_min, y_max, (y_max - y_min)/pixels)

xx, yy = np.meshgrid(eje_x, eje_y)
puntos = np.c_[xx.ravel(), yy.ravel()]
puntos

Z = model.predict(puntos)

Z = Z.reshape(xx.shape)
Z

import matplotlib.pyplot as plt

plt.contourf(xx, yy, Z, alpha= 0.3)

plt.scatter(x_test.horas_esperadas, x_test.precio, c= y_test, s= 1)

# la curva de decision o decission boundery es la linea de abajo y da muy mal, eso explica los resultados tan malos de la clasificacion (57%)

"""##Aula 4: Support Vector Machines y sistemas no lineales"""

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

x = datos[['horas_esperadas', 'precio']]
y = datos.finalizado

seed = 42 #debemos asignar un seed para garantizar la aletoreidad y lograr que el resultado sea replicable, de lo contrario al ejecutar como la celda de arriba sin el seed el resultado cambia cada vez que se ejecuta
np.random.seed(seed) #evitamos tener que especificar el random_state en la linea de abajo

raw_x_train, raw_x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, stratify=y)   #estamos asignando un 25% del DataFrame para pruebas
print(f'Entrenaremos con {len(x_train)} elementos y probaremos con {len(x_test)} elementos')

scaler = StandardScaler()
scaler.fit(raw_x_train)
x_train = scaler.transform(raw_x_train)
x_test = scaler.transform(raw_x_test)

model = SVC()
model.fit(x_train,y_train)
previsiones = model.predict(x_test)

data_x = x_test[:,0]
data_y = x_test[:,1]

x_min = data_x.min()
x_max = data_x.max()
y_min = data_y.min()
y_max = data_y.max()

pixels = 100
eje_x = np.arange(x_min, x_max, (x_max - x_min)/pixels)
eje_y = np.arange(y_min, y_max, (y_max - y_min)/pixels)

xx, yy = np.meshgrid(eje_x, eje_y)
puntos = np.c_[xx.ravel(), yy.ravel()]
Z = model.predict(puntos)
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha= 0.3)
plt.scatter(data_x, data_y, c= y_test, s= 1)

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

"""##Aula 5: Dummy Classifiers y árboles de decisión"""

#la idea es analizar la siguiente base de datos y determinar si un auto va a ser vendido o no

uri = 'https://gist.githubusercontent.com/ahcamachod/1595316a6b37bf39baac355b081d9c3b/raw/98bc94de744764cef0e67922ddfac2a226ad6a6f/car_prices.csv'
datos = pd.read_csv(uri)
datos.head()

mapa = {
        'mileage_per_year':'millas_por_año',
        'model_year':'año_del_modelo',
        'price':'precio',
        'sold':'vendido'
      }

datos = datos.rename(columns=mapa)
datos.sample(3)

cambio = {'no':0, 'yes':1}

datos.vendido = datos.vendido.map(cambio)
datos.sample(3)

from datetime import datetime

año_actual = datetime.today().year
datos['edad_del_modelo'] = año_actual - datos.año_del_modelo
datos.sample(3)

datos['km_por_año'] = datos.millas_por_año * 1.60934
datos.sample(3)

datos = datos.drop(columns=['Unnamed: 0', 'millas_por_año', 'año_del_modelo'], axis= 1)
datos.sample(3)

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

x = datos[['edad_del_modelo', 'km_por_año', 'precio']]
y = datos.vendido

seed = 42 
np.random.seed(seed) 

raw_x_train, raw_x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, stratify=y) 
print(f'Entrenaremos con {len(raw_x_train)} elementos y probaremos con {len(raw_x_test)} elementos')

scaler = StandardScaler()
scaler.fit(raw_x_train)
x_train = scaler.transform(raw_x_train)
x_test = scaler.transform(raw_x_test)

model = SVC()
model.fit(x_train,y_train)
previsiones = model.predict(x_test)

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

from sklearn.dummy import DummyClassifier

dummy = DummyClassifier(strategy = 'stratified')
dummy.fit(x_train, y_train)
exactitud = dummy.score(x_test, y_test)*100
print(f'La exactitud del clasificador Dummy stratified fue: {round(exactitud,2)}%')

from sklearn.dummy import DummyClassifier

dummy = DummyClassifier(strategy = 'most_frequent')
dummy.fit(x_train, y_train)
exactitud = dummy.score(x_test, y_test)*100
print(f'La exactitud del clasificador Dummy most_frequent fue: {round(exactitud,2)}%')

#dependiendo del tipo de estrategia, para nosotros al momento de instanciar nuestro DummyClassifier, entonces nosotros vamos a tener una baseline mejor o peor.
#Digamos la idea, cuando nosotros seleccionemos nuestra baseline es quedarnos con una baseline que tenga sentido, entonces esta most_frequent, pues tiene un valor
# más alto y este es el valor que nosotros tenemos que superar y tenemos que superarlo bien. Aquí, por ejemplo, nosotros los superamos en aproximadamente 18%. 
#Entonces hubo una superación pues bastante grande de este baseline.

"""##Árboles de decisión"""

#usando StandardScaler
from sklearn.tree import DecisionTreeClassifier

x = datos[['edad_del_modelo', 'km_por_año', 'precio']]
y = datos.vendido

seed = 42 
np.random.seed(seed) 

raw_x_train, raw_x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, stratify=y) 
print(f'Entrenaremos con {len(raw_x_train)} elementos y probaremos con {len(raw_x_test)} elementos')

scaler = StandardScaler()
scaler.fit(raw_x_train)
x_train = scaler.transform(raw_x_train)
x_test = scaler.transform(raw_x_test)

model = DecisionTreeClassifier(max_depth=3)
model.fit(x_train,y_train)
previsiones = model.predict(x_test)

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

from sklearn.tree import export_graphviz
import graphviz

features = x.columns
dot_data = export_graphviz(model, feature_names = features)
grafico = graphviz.Source(dot_data)
grafico

#sin estandarizar
from sklearn.tree import DecisionTreeClassifier

x = datos[['edad_del_modelo', 'km_por_año', 'precio']]
y = datos.vendido

seed = 42 
np.random.seed(seed) 

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, stratify=y) 
print(f'Entrenaremos con {len(x_train)} elementos y probaremos con {len(x_test)} elementos')

model = DecisionTreeClassifier(max_depth=3)
model.fit(x_train,y_train)
previsiones = model.predict(x_test)

tasa_de_acierto = accuracy_score(y_test, previsiones)
print(f'La tasa de acierto fue de: {round(tasa_de_acierto*100,2)} %')

from sklearn.tree import export_graphviz
import graphviz

features = x.columns
dot_data = export_graphviz(model, feature_names = features, filled = True, rounded= True, class_names=['No','Si'])
grafico = graphviz.Source(dot_data)
grafico

#a medida que se vuelve mas azul hay mas posibilidades de qeu se venda el auto, y a medida que se vuelve mas naranja menos
#las caracteristicas que mas observa el modelo son el precio y el km_por_año